{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Native2ASCIIEncoding.txt\", \"r\")\n",
    "UAST_text = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/.local/lib/python2.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: This method will be removed in future versions.  Use 'parser.read_file()' instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import re\n",
    "config = configparser.ConfigParser()\n",
    "# config_path = \"/home/nikita/Desktop/prac/config.properties\"  #Enter path of config file here \n",
    "# config.readfp(open(config_path))                             #Read path of config file\n",
    "config.readfp(open(\"config.properties\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for line in UAST_text :\n",
    "    lineTokens = line.split()\n",
    "    tokens = tokens + lineTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for token in tokens :\n",
    "    #print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_stack = []\n",
    "general_stack = []\n",
    "bracket_stack = []\n",
    "result = []\n",
    "class_bracket_count = 0\n",
    "method_bracket_count = 0\n",
    "class_name_flag = 1\n",
    "method_name_flag = 1\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tokens)) :\n",
    "    #print(type_stack)\n",
    "    token = tokens[i]\n",
    "    if(token == \"{\") :\n",
    "        bracket_stack = bracket_stack + [\"{\"]\n",
    "        if(len(type_stack) == 1) :\n",
    "            class_bracket_count = class_bracket_count + 1\n",
    "        elif(len(type_stack) == 2) :\n",
    "            method_bracket_count = method_bracket_count + 1\n",
    "    if(i+2 < (len(tokens)-1)) :\n",
    "        if(token == \"{\" and tokens[i+2] == config.get('Section1', 'class_or_interface_declaration')):\n",
    "            #print(\"?\")\n",
    "            type_stack = type_stack + [config.get('Section1', 'class_or_interface_declaration')]\n",
    "            #print(type_stack) \n",
    "            class_name_flag = 0               #name of class not yet known\n",
    "            class_bracket_count = class_bracket_count + 1\n",
    "    if(i+2 < (len(tokens)-1)) :\n",
    "        if(token == \"{\" and tokens[i+2] == config.get('Section1', 'method_declaration')) :\n",
    "            #print(\"?\")\n",
    "            type_stack = type_stack + [config.get('Section1', 'method_declaration')]\n",
    "            method_name_flag = 0             #name of method not yet known\n",
    "            method_bracket_count = method_bracket_count + 1\n",
    "            class_bracket_count = class_bracket_count + 1\n",
    "    if(token == config.get('Section1', 'internal_type') and tokens[i+1] == config.get('Section1', 'simple_name')):\n",
    "        if(len(type_stack) >= 2 and method_name_flag == 0) :\n",
    "            method_name = tokens[i+17]\n",
    "            method_name_flag = 1    #name of method known\n",
    "            method_info = [class_name, method_name]\n",
    "            #print(method_info)\n",
    "        elif(len(type_stack) == 1 and class_name_flag == 0) :\n",
    "            class_name = tokens[i+17]\n",
    "            class_name_flag = 1           \n",
    "    \n",
    "    if(token == config.get('Section1', 'token') and class_name_flag == 1 and method_name_flag == 1 and len(type_stack) >= 2) :\n",
    "        data = data + [tokens[i+1]]\n",
    "           \n",
    "    if(token == \"}\") :\n",
    "        bracket_stack.pop()\n",
    "        if(len(type_stack) >= 2) :\n",
    "            method_bracket_count = method_bracket_count - 1\n",
    "            class_bracket_count = class_bracket_count - 1\n",
    "            if(method_bracket_count == 0) :\n",
    "                type_stack.pop()\n",
    "                method_data = method_info + data\n",
    "                #print(method_data)\n",
    "                result = result + [method_data]\n",
    "                #data = []\n",
    "                method_info = []\n",
    "        if(len(type_stack) == 1) :\n",
    "            #print(class_bracket_count)\n",
    "            class_bracket_count = class_bracket_count - 1\n",
    "            if(class_bracket_count == 0) :\n",
    "                type_stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_summary = []\n",
    "for i in range(0, len(result)) :\n",
    "    method_data = result[i]\n",
    "    if (method_data == []) :\n",
    "        continue\n",
    "    class_name = method_data[0].replace(\"\\\"\", \"\")\n",
    "    method_name = method_data[1].replace(\"\\\"\", \"\")\n",
    "    method_summary = [class_name, method_name]\n",
    "    method_words = []\n",
    "    for j in range(2, len(method_data)) :\n",
    "        token = method_data[j]\n",
    "        token = token.replace(\"\\\"\", \"\")\n",
    "        if(len(token) >= 4 and (\"\\\\\" not in token ) and (\":\" not in token )) :\n",
    "            method_words = method_words + [token]\n",
    "    method_words = list(set(method_words))\n",
    "    code_summary = code_summary + [method_summary + method_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  gettextreader\n",
      " reader\n",
      " native2asciireader\n",
      " native2asciiencoding\n",
      " ioexception\n",
      " inputstream\n",
      " false\n",
      "Top terms per cluster:\n",
      "Cluster 0:  gettextwriter\n",
      " writer\n",
      " reader\n",
      " outputstream\n",
      " native2asciireader\n",
      " native2asciiencoding\n",
      " ioexception\n",
      " inputstream\n",
      " gettextreader\n",
      " filterwriter\n",
      "Top terms per cluster:\n",
      "Cluster 0:  writer\n",
      " reader\n",
      " outputstream\n",
      " native2asciireader\n",
      " ioexception\n",
      " inputstream\n",
      " gettextwriter\n",
      " gettextreader\n",
      " filterwriter\n",
      " false\n",
      "Top terms per cluster:\n",
      "Cluster 0:  append\n",
      " write\n",
      " asciiencoding\n",
      " charsequence\n",
      " equals\n",
      " false\n",
      " filterwriter\n",
      " gettextreader\n",
      " gettextwriter\n",
      " inputstream\n",
      "Top terms per cluster:\n",
      "Cluster 0:  append\n",
      " inputstream\n",
      " asciiencoding\n",
      " char\n",
      " charsequence\n",
      " equals\n",
      " false\n",
      " filterwriter\n",
      " gettextreader\n",
      " gettextwriter\n",
      "Top terms per cluster:\n",
      "Cluster 0:  write\n",
      " writer\n",
      " asciiencoding\n",
      " char\n",
      " charsequence\n",
      " equals\n",
      " false\n",
      " filterwriter\n",
      " gettextreader\n",
      " gettextwriter\n",
      "Top terms per cluster:\n",
      "Cluster 0:  write\n",
      " writer\n",
      " ioexception\n",
      " asciiencoding\n",
      " cbuf\n",
      " char\n",
      " charsequence\n",
      " equals\n",
      " false\n",
      " filterwriter\n",
      "Top terms per cluster:\n",
      "Cluster 0:  write\n",
      " writer\n",
      " asciiencoding\n",
      " cbuf\n",
      " char\n",
      " charsequence\n",
      " equals\n",
      " false\n",
      " filterwriter\n",
      " gettextreader\n",
      "Top terms per cluster:\n",
      "Cluster 0:  write\n",
      " ioexception\n",
      " inputstream\n",
      " gettextwriter\n",
      " gettextreader\n",
      " format\n",
      " filterwriter\n",
      " false\n",
      " equals\n",
      " writer\n",
      "Top terms per cluster:\n",
      "Cluster 0:  write\n",
      " ioexception\n",
      " inputstream\n",
      " gettextwriter\n",
      " gettextreader\n",
      " format\n",
      " filterwriter\n",
      " false\n",
      " equals\n",
      " writer\n",
      "Top terms per cluster:\n",
      "Cluster 0:  getpermissivetextreader\n",
      " writer\n",
      " ioexception\n",
      " gettextwriter\n",
      " gettextreader\n",
      " format\n",
      " filterwriter\n",
      " false\n",
      " equals\n",
      " charsequence\n",
      "Top terms per cluster:\n",
      "Cluster 0:  gettextreader\n",
      " writer\n",
      " write\n",
      " inputstream\n",
      " illegalaccessexception\n",
      " gettextwriter\n",
      " getpermissivetextreader\n",
      " format\n",
      " filterwriter\n",
      " false\n",
      "Top terms per cluster:\n",
      "Cluster 0:  getpermissivetextreader\n",
      " writer\n",
      " write\n",
      " inputstream\n",
      " illegalaccessexception\n",
      " gettextwriter\n",
      " gettextreader\n",
      " format\n",
      " filterwriter\n",
      " false\n",
      "Top terms per cluster:\n",
      "Cluster 0:  inputstream\n",
      " gettextreader\n",
      " clazz\n",
      " illegalaccessexception\n",
      " gettextwriter\n",
      " getpermissivetextreader\n",
      " format\n",
      " filterwriter\n",
      " false\n",
      " equals\n",
      "Top terms per cluster:\n",
      "Cluster 0:  native2asciireader\n",
      " read\n",
      " writer\n",
      " false\n",
      " invocationtargetexception\n",
      " integer\n",
      " instantiationexception\n",
      " inputstream\n",
      " illegalaccessexception\n",
      " greater_equals\n",
      "Top terms per cluster:\n",
      "Cluster 0:  read\n",
      " native2asciireader\n",
      " length\n",
      " invocationtargetexception\n",
      " integer\n",
      " instantiationexception\n",
      " inputstream\n",
      " illegalaccessexception\n",
      " greater_equals\n",
      " greater\n",
      "Top terms per cluster:\n",
      "Cluster 0:  read\n",
      " native2asciireader\n",
      " length\n",
      " invocationtargetexception\n",
      " integer\n",
      " instantiationexception\n",
      " inputstream\n",
      " illegalaccessexception\n",
      " greater_equals\n",
      " greater\n",
      "Top terms per cluster:\n",
      "Cluster 0:  native2asciireader\n",
      " read\n",
      " writer\n",
      " length\n",
      " invocationtargetexception\n",
      " integer\n",
      " instantiationexception\n",
      " inputstream\n",
      " illegalaccessexception\n",
      " greater_equals\n",
      "Top terms per cluster:\n",
      "Cluster 0:  readn\n",
      " native2asciireader\n",
      " writer\n",
      " greater_equals\n",
      " format\n",
      " getpermissivetextreader\n",
      " gettextreader\n",
      " gettextwriter\n",
      " greater\n",
      " illegalaccessexception\n",
      "Top terms per cluster:\n",
      "Cluster 0:  skip\n",
      " native2asciireader\n",
      " writer\n",
      " inputstream\n",
      " gettextreader\n",
      " gettextwriter\n",
      " greater\n",
      " greater_equals\n",
      " illegalaccessexception\n",
      " illegalargumentexception\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "for documents in code_summary :\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "\n",
    "    true_k = 1\n",
    "    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "    model.fit(X)\n",
    "\n",
    "    print(\"Top terms per cluster:\")\n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i),\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
